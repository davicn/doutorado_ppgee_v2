{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação de janelas de tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "                     .appName('Doutorado')\n",
    "                     .getOrCreate())\n",
    "\n",
    "path_data = '/media/davi/6A81-05CF/physionet.org/files/siena-scalp-eeg/1.0.0/PN00/'\n",
    "infos_path = '/home/davi/Documentos/doutorado_ppgee_v2/data/siena_infos.json'\n",
    "\n",
    "infos = pd.read_json(infos_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação ECG-EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "\n",
    "files = [dir_[0] for dir_ in walk(path_data)][1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando período Ictal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_ictal(file: str):\n",
    "    df = spark.read.parquet(file)\n",
    "\n",
    "    eeg_ch = [col for col in df.schema.names if 'EEG' in col]\n",
    "    eeg_ch.append('label')\n",
    "    eeg_ch.append('__index_level_0__')\n",
    "\n",
    "    ecg_ch = [col for col in df.schema.names if 'EKG' in col]\n",
    "    ecg_ch.append('label')\n",
    "    ecg_ch.append('__index_level_0__')\n",
    "\n",
    "    (df.select(ecg_ch)\n",
    "       .filter(col(\"label\") == 'I')\n",
    "       .write\n",
    "       .mode(\"overwrite\")\n",
    "       .parquet(f\"{file}/ICTAL/EKG\"))\n",
    "\n",
    "    (df.select(eeg_ch)\n",
    "       .filter(col(\"label\") == 'I')\n",
    "       .write\n",
    "       .mode(\"overwrite\")\n",
    "       .parquet(f\"{file}/ICTAL/EEG\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/01 13:29:19 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    pipeline_ictal(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando período Não-Ictal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_N_ictal(file: str, info: dict):\n",
    "    freq = info['sfreq']\n",
    "    start = info['seizure_start_sec']*freq\n",
    "    stop = info['seizure_end_sec']*freq\n",
    "    total = info['total_seizure']*freq\n",
    "\n",
    "    fim = int(start - (20*freq))\n",
    "    inicio = int(fim - total)\n",
    "\n",
    "    df = spark.read.parquet(file)\n",
    "\n",
    "    eeg_ch = [col for col in df.schema.names if 'EEG' in col]\n",
    "    eeg_ch.append('label')\n",
    "    eeg_ch.append('__index_level_0__')\n",
    "\n",
    "    ecg_ch = [col for col in df.schema.names if 'EKG' in col]\n",
    "    ecg_ch.append('label')\n",
    "    ecg_ch.append('__index_level_0__')\n",
    "\n",
    "    (df.select(ecg_ch)\n",
    "     .filter(col('__index_level_0__')\n",
    "             .between(inicio, fim))\n",
    "     .write\n",
    "     .mode(\"overwrite\")\n",
    "     .parquet(f\"{file}/N_ICTAL/EKG\"))\n",
    "\n",
    "    (df.select(eeg_ch)\n",
    "        .filter(col('__index_level_0__')\n",
    "                .between(inicio, fim))\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .parquet(f\"{file}/N_ICTAL/EEG\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# for file in files:\n",
    "#     pipeline_ictal(file)\n",
    "\n",
    "for index, row in infos.iterrows():\n",
    "    info = dict(row)\n",
    "    file = f\"{path_data}{info['name'].replace('.edf','')}\"\n",
    "    pipeline_N_ictal(file=file, info=info)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e03adb9c4bbc7c636a7cb490e01abc5328f7132a16cbef2ed244d180aaa11cf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
